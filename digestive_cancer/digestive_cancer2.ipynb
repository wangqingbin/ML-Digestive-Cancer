{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入所需要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sympy import im\n",
    "import warnings\n",
    "import logging\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable     | Definition       | Key                                            |\n",
    "|--------------|------------------|------------------------------------------------|\n",
    "| index        | 病人编号         |                                                |\n",
    "| Source       | 病人来源         | 0：国外数据集 1：国内数据集                    |\n",
    "| Sex          | 性别             | 0：男 1：女                                    |\n",
    "| Age          | 年龄             |                                                |\n",
    "| BMI          | 身高体重比       |                                                |\n",
    "| Diagnostic   | 癌症类型         |                                                |\n",
    "| Stage        | 癌症分期         |                                                |\n",
    "| NLR          | 中性/淋巴        |                                                |\n",
    "| HGB          | 血红蛋白         |                                                |\n",
    "| Surgury      | 之前是否进行手术 | 0：未手术 1：已手术                            |\n",
    "| Chemo        | 是否同时进行化疗 | 0：否；1：是                                   |\n",
    "| Radiotherapy | 是否同时进行化疗 | 0：否；1：是                                   |\n",
    "| Drug         | 免疫药物         | 0：PD1/PDL1orCTLA4；1：Combo                   |\n",
    "| MSI          | 微卫星不稳定性   | 0：MSS； 1：MSI-H                              |\n",
    "| GeneMutation | 基因突变         | 0.0：hert2阴性；1.0：hert2阳性；2.0：K-RAS阳性 |\n",
    "| CPS          | 联合阳性评分     |                                                |\n",
    "| Ki67         | 细胞增殖标志物   |                                                |\n",
    "| Response     | 免疫应答         | 0：无应答；1：有应答                           |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Diagnostic</th>\n",
       "      <th>Stage</th>\n",
       "      <th>NLR</th>\n",
       "      <th>HGB</th>\n",
       "      <th>Surgury</th>\n",
       "      <th>Chemo</th>\n",
       "      <th>Radiotherapy</th>\n",
       "      <th>Drug</th>\n",
       "      <th>MSI</th>\n",
       "      <th>GeneMutation</th>\n",
       "      <th>CPS</th>\n",
       "      <th>ki67</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.871321</td>\n",
       "      <td>30.1</td>\n",
       "      <td>Esophageal</td>\n",
       "      <td>4</td>\n",
       "      <td>2.44</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.603696</td>\n",
       "      <td>22.3</td>\n",
       "      <td>Esophageal</td>\n",
       "      <td>4</td>\n",
       "      <td>3.40</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63.586585</td>\n",
       "      <td>28.4</td>\n",
       "      <td>Esophageal</td>\n",
       "      <td>4</td>\n",
       "      <td>8.00</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58.896646</td>\n",
       "      <td>19.4</td>\n",
       "      <td>Esophageal</td>\n",
       "      <td>4</td>\n",
       "      <td>8.71</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60.692676</td>\n",
       "      <td>37.4</td>\n",
       "      <td>Esophageal</td>\n",
       "      <td>4</td>\n",
       "      <td>2.63</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source  Sex        Age   BMI  Diagnostic  Stage   NLR    HGB  Surgury  \\\n",
       "0       0    1  43.871321  30.1  Esophageal      4  2.44  120.0        0   \n",
       "1       0    0  70.603696  22.3  Esophageal      4  3.40  127.0        0   \n",
       "2       0    1  63.586585  28.4  Esophageal      4  8.00   96.0        0   \n",
       "3       0    0  58.896646  19.4  Esophageal      4  8.71  115.0        0   \n",
       "4       0    1  60.692676  37.4  Esophageal      4  2.63  142.0        0   \n",
       "\n",
       "   Chemo  Radiotherapy  Drug  MSI  GeneMutation  CPS  ki67  Response  \n",
       "0      0             0     0  0.0           NaN  NaN   NaN         0  \n",
       "1      0             0     0  0.0           NaN  NaN   NaN         1  \n",
       "2      0             0     0  0.0           NaN  NaN   NaN         0  \n",
       "3      0             0     0  0.0           NaN  NaN   NaN         0  \n",
       "4      0             0     0  0.0           NaN  NaN   NaN         0  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"digestive_cancer.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 17 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Source        506 non-null    int64  \n",
      " 1   Sex           506 non-null    int64  \n",
      " 2   Age           506 non-null    float64\n",
      " 3   BMI           505 non-null    float64\n",
      " 4   Diagnostic    506 non-null    object \n",
      " 5   Stage         506 non-null    int64  \n",
      " 6   NLR           506 non-null    float64\n",
      " 7   HGB           506 non-null    float64\n",
      " 8   Surgury       506 non-null    int64  \n",
      " 9   Chemo         506 non-null    int64  \n",
      " 10  Radiotherapy  506 non-null    int64  \n",
      " 11  Drug          506 non-null    int64  \n",
      " 12  MSI           427 non-null    float64\n",
      " 13  GeneMutation  184 non-null    float64\n",
      " 14  CPS           137 non-null    float64\n",
      " 15  ki67          67 non-null     float64\n",
      " 16  Response      506 non-null    int64  \n",
      "dtypes: float64(8), int64(8), object(1)\n",
      "memory usage: 67.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标明哪些列是数值型，哪些是类别型\n",
    "category_columns = ['Sex', 'Diagnostic', 'Stage', 'Surgury', 'Chemo', 'Radiotherapy', 'Drug', 'MSI', 'GeneMutation']\n",
    "numeric_columns = ['Age', 'BMI', 'NLR', 'HGB', 'CPS', 'ki67']\n",
    "hospital_source = ['Source']\n",
    "target = ['Response']\n",
    "diagnostic_encoder = LabelEncoder()\n",
    "data['Diagnostic'] = diagnostic_encoder.fit_transform(data['Diagnostic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算类别权重\n",
    "# 计算正负样本比例\n",
    "y = data['Response']\n",
    "scale_pos_weight = np.sum(y == 0) / np.sum(y == 1)  # 负类样本数 / 正类样本数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 划分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex               0\n",
      "Age               0\n",
      "BMI               1\n",
      "Diagnostic        0\n",
      "Stage             0\n",
      "NLR               0\n",
      "HGB               0\n",
      "Surgury           0\n",
      "Chemo             0\n",
      "Radiotherapy      0\n",
      "Drug              0\n",
      "MSI              63\n",
      "GeneMutation    257\n",
      "CPS             296\n",
      "ki67            352\n",
      "dtype: int64\n",
      "Sex              0\n",
      "Age              0\n",
      "BMI              0\n",
      "Diagnostic       0\n",
      "Stage            0\n",
      "NLR              0\n",
      "HGB              0\n",
      "Surgury          0\n",
      "Chemo            0\n",
      "Radiotherapy     0\n",
      "Drug             0\n",
      "MSI             16\n",
      "GeneMutation    65\n",
      "CPS             73\n",
      "ki67            87\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 由于目前的数据集是将国内数据集和国外数据集合并到一起的，但两种数据集存在明显的差异，因此在划分训练集和测试集时，需要将两种数据集分开单独划分\n",
    "data_in = data[data['Source'] == 1]\n",
    "data_out = data[data['Source'] == 0]\n",
    "# 由于在划分训练集和测试集时，需要保证训练集和测试集的类别分布是相同的，除此之外，还要保证每个类别中癌症类别的分布也是相同的，因此需要组建Diagnostic和Response的联合变量\n",
    "data_in_stratify = data_in['Diagnostic'].astype(str) + '_' + data_in['Response'].astype(str)\n",
    "data_out_stratify = data_out['Diagnostic'].astype(str) + '_' + data_out['Response'].astype(str)\n",
    "# 区分数据的特征和目标\n",
    "data_in_X = data_in.drop(columns=['Response', 'Source'])\n",
    "data_in_y = data_in['Response']\n",
    "data_out_X = data_out.drop(columns=['Response', 'Source'])\n",
    "data_out_y = data_out['Response']\n",
    "# 划分训练集和测试集\n",
    "data_in_train_X, data_in_test_X, data_in_train_y, data_in_test_y = train_test_split(data_in_X, data_in_y, test_size=0.2, random_state=42, stratify=data_in_stratify)\n",
    "data_out_train_X, data_out_test_X, data_out_train_y, data_out_test_y = train_test_split(data_out_X, data_out_y, test_size=0.2, random_state=42, stratify=data_out_stratify)\n",
    "# 将两家医院的数据进行合并\n",
    "data_train_X = pd.concat([data_in_train_X, data_out_train_X], ignore_index=True)\n",
    "data_train_y = pd.concat([data_in_train_y, data_out_train_y], ignore_index=True)\n",
    "data_test_X = pd.concat([data_in_test_X, data_out_test_X], ignore_index=True)\n",
    "data_test_y = pd.concat([data_in_test_y, data_out_test_y], ignore_index=True)\n",
    "# 查看数据集的缺失值情况\n",
    "print(data_train_X.isnull().sum())\n",
    "print(data_test_X.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 填充数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 完成训练集、测试集的划分之后，开始填充数据集\n",
    "# # 将训练数据集中的缺失值使用miceforest库进行填充，填充训练完成以后再对测试集的数据进行填充\n",
    "# # 统计训练集和测试集的缺失值情况\n",
    "# # print(data_train_X.isnull().sum())\n",
    "# # print(data_test_X.isnull().sum())\n",
    "# # kernal = mf.ImputationKernel(data=data_train_X, datasets=1, save_all_iterations=True, random_state=42)\n",
    "# # kernal.mice(1)\n",
    "# # # 获取填补后的数据\n",
    "# # data_train_X = kernal.complete_data(dataset=0)\n",
    "# # # 对测试集的数据进行填补\n",
    "# # data_test_X = kernal.impute_new_data(new_data=data_test_X, random_state=42)\n",
    "# # # 统计训练集和测试集的缺失值情况\n",
    "# # print(data_train_X.isnull().sum())\n",
    "# # print(data_test_X.isnull().sum())\n",
    "# # 由于上述插值过程太过耗时，所以改用KNN插值法补充数据\n",
    "# # print(data['Diagnostic'].dtype)\n",
    "# from sklearn.impute import KNNImputer\n",
    "# # 对类别变量进行OneHot编码\n",
    "# onehot = OneHotEncoder(sparse=False)\n",
    "# # 对训练集的类别变量进行编码\n",
    "# categorical_train = onehot.fit_transform(data_train_X[category_columns])\n",
    "# categorical_train_df = pd.DataFrame(\n",
    "#     categorical_train,\n",
    "#     columns=onehot.get_feature_names_out(category_columns)\n",
    "# )\n",
    "\n",
    "# # 对测试集的类别变量进行编码\n",
    "# categorical_test = onehot.transform(data_test_X[category_columns])\n",
    "# categorical_test_df = pd.DataFrame(\n",
    "#     categorical_test,\n",
    "#     columns=onehot.get_feature_names_out(category_columns)\n",
    "# )\n",
    "# print(\"实际的列名:\", data_train_X.columns.tolist())\n",
    "# # 将数值型变量与编码后的类别变量合并\n",
    "# data_train_encoded = pd.concat([data_train_X[numeric_columns], categorical_train_df], axis=1)\n",
    "# data_test_encoded = pd.concat([data_test_X[numeric_columns], categorical_test_df], axis=1)\n",
    "# # 创建KNNImputer对象，指定邻居数\n",
    "# knn_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# # 对训练集进行填充\n",
    "# data_train_X_filled = pd.DataFrame(\n",
    "#     knn_imputer.fit_transform(data_train_X),\n",
    "#     columns=data_train_X.columns\n",
    "# )\n",
    "\n",
    "# # 对测试集进行填充\n",
    "# data_test_X_filled = pd.DataFrame(\n",
    "#     knn_imputer.transform(data_test_X),\n",
    "#     columns=data_test_X.columns\n",
    "# )\n",
    "\n",
    "# # 检查填充后的数据集是否还有缺失值\n",
    "\n",
    "# print(data_train_X_filled.isnull().sum())\n",
    "# print(data_test_X_filled.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex               0\n",
      "Age               0\n",
      "BMI               1\n",
      "Diagnostic        0\n",
      "Stage             0\n",
      "NLR               0\n",
      "HGB               0\n",
      "Surgury           0\n",
      "Chemo             0\n",
      "Radiotherapy      0\n",
      "Drug              0\n",
      "MSI              63\n",
      "GeneMutation    257\n",
      "CPS             296\n",
      "ki67            352\n",
      "dtype: int64\n",
      "Sex              0\n",
      "Age              0\n",
      "BMI              0\n",
      "Diagnostic       0\n",
      "Stage            0\n",
      "NLR              0\n",
      "HGB              0\n",
      "Surgury          0\n",
      "Chemo            0\n",
      "Radiotherapy     0\n",
      "Drug             0\n",
      "MSI             16\n",
      "GeneMutation    65\n",
      "CPS             73\n",
      "ki67            87\n",
      "dtype: int64\n",
      "[IterativeImputer] Completing matrix with shape (404, 15)\n",
      "[IterativeImputer] Change: 55.130149229736524, scaled tolerance: 0.166 \n",
      "[IterativeImputer] Change: 26.526402231028342, scaled tolerance: 0.166 \n",
      "[IterativeImputer] Change: 24.02249501058944, scaled tolerance: 0.166 \n",
      "[IterativeImputer] Change: 11.49922344217877, scaled tolerance: 0.166 \n",
      "[IterativeImputer] Change: 12.835722555471836, scaled tolerance: 0.166 \n",
      "[IterativeImputer] Change: 13.49036557753276, scaled tolerance: 0.166 \n",
      "[IterativeImputer] Change: 11.094995955963292, scaled tolerance: 0.166 \n",
      "[IterativeImputer] Change: 19.00969159453738, scaled tolerance: 0.166 \n",
      "[IterativeImputer] Change: 12.610715333273532, scaled tolerance: 0.166 \n",
      "[IterativeImputer] Change: 10.188863360884078, scaled tolerance: 0.166 \n",
      "[IterativeImputer] Completing matrix with shape (102, 15)\n",
      "训练集缺失值情况：\n",
      "0\n",
      "\n",
      "测试集缺失值情况：\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "need_impute_category_columns = ['MSI', 'GeneMutation']\n",
    "# 1. 首先对需要进行填充缺失值类别变量进行标签编码（而不是独热编码）\n",
    "label_encoders = {}\n",
    "data_train_encoded = data_train_X.copy()\n",
    "data_test_encoded = data_test_X.copy()\n",
    "\n",
    "for col in need_impute_category_columns:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    # 对非缺失值进行编码\n",
    "    mask = data_train_X[col].notna()\n",
    "    data_train_encoded.loc[mask, col] = label_encoders[col].fit_transform(data_train_X.loc[mask, col])\n",
    "    mask = data_test_X[col].notna()\n",
    "    data_test_encoded.loc[mask, col] = label_encoders[col].transform(data_test_X.loc[mask, col])\n",
    "# 打印编码后每列数据的缺失值情况\n",
    "print(data_train_encoded.isnull().sum())\n",
    "print(data_test_encoded.isnull().sum())\n",
    "\n",
    "# 2. 分别为数值型和类别型特征创建插补器\n",
    "# 数值型特征的插补器\n",
    "numeric_imputer = IterativeImputer(\n",
    "    estimator=RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        random_state=42\n",
    "    ),\n",
    "    random_state=42,\n",
    "    max_iter=10,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 3. 进行联合填充\n",
    "# 将所有特征一起输入到插补器中\n",
    "data_train_filled = pd.DataFrame(\n",
    "    numeric_imputer.fit_transform(data_train_encoded),\n",
    "    columns=data_train_encoded.columns,\n",
    "    index=data_train_encoded.index\n",
    ")\n",
    "\n",
    "data_test_filled = pd.DataFrame(\n",
    "    numeric_imputer.transform(data_test_encoded),\n",
    "    columns=data_test_encoded.columns,\n",
    "    index=data_test_encoded.index\n",
    ")\n",
    "\n",
    "# 4. 对类别型变量的填充值进行四舍五入\n",
    "for col in need_impute_category_columns:\n",
    "    data_train_filled[col] = np.round(data_train_filled[col]).astype(int)\n",
    "    data_test_filled[col] = np.round(data_test_filled[col]).astype(int)\n",
    "\n",
    "# 5. 将类别变量转换回原始的类别标签（可选）\n",
    "for col in need_impute_category_columns:\n",
    "    data_train_filled[col] = label_encoders[col].inverse_transform(data_train_filled[col])\n",
    "    data_test_filled[col] = label_encoders[col].inverse_transform(data_test_filled[col])\n",
    "\n",
    "# 6. 最后进行OneHot编码\n",
    "onehot = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "categorical_train = onehot.fit_transform(data_train_filled[category_columns])\n",
    "categorical_train_df = pd.DataFrame(\n",
    "    categorical_train,\n",
    "    columns=onehot.get_feature_names_out(category_columns),\n",
    "    index=data_train_filled.index\n",
    ")\n",
    "\n",
    "categorical_test = onehot.transform(data_test_filled[category_columns])\n",
    "categorical_test_df = pd.DataFrame(\n",
    "    categorical_test,\n",
    "    columns=onehot.get_feature_names_out(category_columns),\n",
    "    index=data_test_filled.index\n",
    ")\n",
    "\n",
    "# 7. 合并最终的特征\n",
    "data_train_final = pd.concat([data_train_filled[numeric_columns], categorical_train_df], axis=1)\n",
    "data_test_final = pd.concat([data_test_filled[numeric_columns], categorical_test_df], axis=1)\n",
    "\n",
    "# 8. 验证结果\n",
    "print(\"训练集缺失值情况：\")\n",
    "print(data_train_final.isnull().sum().sum())\n",
    "print(\"\\n测试集缺失值情况：\")\n",
    "print(data_test_final.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'BMI', 'NLR', 'HGB', 'CPS', 'ki67', 'Sex_0.0', 'Sex_1.0',\n",
      "       'Diagnostic_0.0', 'Diagnostic_1.0', 'Diagnostic_2.0', 'Stage_1.0',\n",
      "       'Stage_2.0', 'Stage_3.0', 'Stage_4.0', 'Surgury_0.0', 'Surgury_1.0',\n",
      "       'Chemo_0.0', 'Chemo_1.0', 'Radiotherapy_0.0', 'Radiotherapy_1.0',\n",
      "       'Drug_0.0', 'Drug_1.0', 'MSI_0.0', 'MSI_1.0', 'GeneMutation_0.0',\n",
      "       'GeneMutation_1.0', 'GeneMutation_2.0'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data_train_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>NLR</th>\n",
       "      <th>HGB</th>\n",
       "      <th>CPS</th>\n",
       "      <th>ki67</th>\n",
       "      <th>Sex_0.0</th>\n",
       "      <th>Sex_1.0</th>\n",
       "      <th>Diagnostic_0.0</th>\n",
       "      <th>Diagnostic_1.0</th>\n",
       "      <th>...</th>\n",
       "      <th>Chemo_1.0</th>\n",
       "      <th>Radiotherapy_0.0</th>\n",
       "      <th>Radiotherapy_1.0</th>\n",
       "      <th>Drug_0.0</th>\n",
       "      <th>Drug_1.0</th>\n",
       "      <th>MSI_0.0</th>\n",
       "      <th>MSI_1.0</th>\n",
       "      <th>GeneMutation_0.0</th>\n",
       "      <th>GeneMutation_1.0</th>\n",
       "      <th>GeneMutation_2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71.0</td>\n",
       "      <td>16.730</td>\n",
       "      <td>4.333</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>65.159918</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75.0</td>\n",
       "      <td>19.670</td>\n",
       "      <td>1.857</td>\n",
       "      <td>143.0</td>\n",
       "      <td>17.170976</td>\n",
       "      <td>63.601667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71.0</td>\n",
       "      <td>20.980</td>\n",
       "      <td>3.833</td>\n",
       "      <td>124.0</td>\n",
       "      <td>9.386995</td>\n",
       "      <td>56.021000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63.0</td>\n",
       "      <td>21.519</td>\n",
       "      <td>2.357</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.483489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76.0</td>\n",
       "      <td>18.780</td>\n",
       "      <td>2.945</td>\n",
       "      <td>105.0</td>\n",
       "      <td>13.270881</td>\n",
       "      <td>62.586606</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     BMI    NLR    HGB        CPS       ki67  Sex_0.0  Sex_1.0  \\\n",
       "0  71.0  16.730  4.333   99.0   2.000000  65.159918      1.0      0.0   \n",
       "1  75.0  19.670  1.857  143.0  17.170976  63.601667      1.0      0.0   \n",
       "2  71.0  20.980  3.833  124.0   9.386995  56.021000      0.0      1.0   \n",
       "3  63.0  21.519  2.357  105.0   0.000000  66.483489      0.0      1.0   \n",
       "4  76.0  18.780  2.945  105.0  13.270881  62.586606      1.0      0.0   \n",
       "\n",
       "   Diagnostic_0.0  Diagnostic_1.0  ...  Chemo_1.0  Radiotherapy_0.0  \\\n",
       "0             0.0             0.0  ...        1.0               0.0   \n",
       "1             1.0             0.0  ...        1.0               1.0   \n",
       "2             0.0             1.0  ...        1.0               0.0   \n",
       "3             0.0             0.0  ...        1.0               1.0   \n",
       "4             0.0             0.0  ...        1.0               1.0   \n",
       "\n",
       "   Radiotherapy_1.0  Drug_0.0  Drug_1.0  MSI_0.0  MSI_1.0  GeneMutation_0.0  \\\n",
       "0               1.0       1.0       0.0      0.0      1.0               1.0   \n",
       "1               0.0       1.0       0.0      1.0      0.0               0.0   \n",
       "2               1.0       1.0       0.0      1.0      0.0               0.0   \n",
       "3               0.0       1.0       0.0      1.0      0.0               1.0   \n",
       "4               0.0       1.0       0.0      0.0      1.0               0.0   \n",
       "\n",
       "   GeneMutation_1.0  GeneMutation_2.0  \n",
       "0               0.0               0.0  \n",
       "1               0.0               1.0  \n",
       "2               0.0               1.0  \n",
       "3               0.0               0.0  \n",
       "4               1.0               0.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义5种不同的机器学习模型，并进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Model saved to weight/logistic_regression.pkl\n",
      "Training K-Nearest Neighbors...\n",
      "Model saved to weight/k-nearest_neighbors.pkl\n",
      "Training Random Forest...\n",
      "Model saved to weight/random_forest.pkl\n",
      "Training Naive Bayes...\n",
      "Model saved to weight/naive_bayes.pkl\n",
      "Training QDA...\n",
      "Model saved to weight/qda.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        class_weight='balanced',\n",
    "        C=1.0,\n",
    "        solver='lbfgs'\n",
    "    ),  # LogisticRegression默认就会输出概率\n",
    "    \n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(\n",
    "        n_neighbors=5,\n",
    "        weights='distance',\n",
    "        metric='minkowski',\n",
    "        n_jobs=-1\n",
    "    ),  # KNeighborsClassifier默认就会输出概率\n",
    "    \n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        class_weight='balanced',\n",
    "        n_jobs=-1\n",
    "    ),  # RandomForestClassifier默认就会输出概率\n",
    "    \n",
    "    'Naive Bayes': GaussianNB(\n",
    "        var_smoothing=1e-9,\n",
    "        priors=None  # 可以设置先验概率\n",
    "    ),  # GaussianNB默认就会输出概率\n",
    "    \n",
    "    'QDA': QuadraticDiscriminantAnalysis(\n",
    "        priors=None,  # 可以设置先验概率,None表示使用训练数据中的类别频率\n",
    "        reg_param=0.0,  # 正则化参数,用于处理协方差估计\n",
    "        store_covariance=True,  # 是否存储协方差矩阵\n",
    "        tol=1e-4  # 奇异值分解的容差阈值\n",
    "    )\n",
    "}\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# 创建权重保存目录\n",
    "if not os.path.exists('weight'):\n",
    "    os.makedirs('weight')\n",
    "\n",
    "# 训练并保存模型\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    \n",
    "    # 训练模型\n",
    "    model.fit(data_train_final, data_train_y)\n",
    "    \n",
    "    # 保存模型\n",
    "    save_path = f'weight/{model_name.lower().replace(\" \", \"_\")}.pkl'\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"Model saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测测试集，并计算相应指标，绘图等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "评估 Logistic Regression 模型...\n",
      "AUC: 0.7921\n",
      "Accuracy: 0.7451\n",
      "Sensitivity: 0.7667\n",
      "Specificity: 0.7143\n",
      "PPV: 0.7931\n",
      "NPV: 0.6818\n",
      "\n",
      "混淆矩阵:\n",
      "[[30 12]\n",
      " [14 46]]\n",
      "\n",
      "评估 K-Nearest Neighbors 模型...\n",
      "AUC: 0.6758\n",
      "Accuracy: 0.6176\n",
      "Sensitivity: 0.6833\n",
      "Specificity: 0.5238\n",
      "PPV: 0.6721\n",
      "NPV: 0.5366\n",
      "\n",
      "混淆矩阵:\n",
      "[[22 20]\n",
      " [19 41]]\n",
      "\n",
      "评估 Random Forest 模型...\n",
      "AUC: 0.8075\n",
      "Accuracy: 0.7451\n",
      "Sensitivity: 0.8333\n",
      "Specificity: 0.6190\n",
      "PPV: 0.7576\n",
      "NPV: 0.7222\n",
      "\n",
      "混淆矩阵:\n",
      "[[26 16]\n",
      " [10 50]]\n",
      "\n",
      "评估 Naive Bayes 模型...\n",
      "AUC: 0.7849\n",
      "Accuracy: 0.7353\n",
      "Sensitivity: 0.7500\n",
      "Specificity: 0.7143\n",
      "PPV: 0.7895\n",
      "NPV: 0.6667\n",
      "\n",
      "混淆矩阵:\n",
      "[[30 12]\n",
      " [15 45]]\n",
      "\n",
      "评估 QDA 模型...\n",
      "AUC: 0.7685\n",
      "Accuracy: 0.6863\n",
      "Sensitivity: 0.7167\n",
      "Specificity: 0.6429\n",
      "PPV: 0.7414\n",
      "NPV: 0.6136\n",
      "\n",
      "混淆矩阵:\n",
      "[[27 15]\n",
      " [17 43]]\n"
     ]
    }
   ],
   "source": [
    "def cal_bin_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    the function is used to calculate the corresponding metrics for binary classification,\n",
    "    including 二分类准确率, 灵敏度, 特异性, PPV, NPV, AUC\n",
    "    :param y_true: 一维数组标签, [1, 0, 1, ...]\n",
    "    :param y_pred: 二维预测数组, [num_sample, 2]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    binary_accracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    # 利用sklearn的接口计算得到混淆矩阵\n",
    "    binary_confusion_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
    "    # 接下来利用二分类的混淆矩阵计算各种指标，包括灵敏度，特异性，PPV, NPV\n",
    "    tp = binary_confusion_matrix[1][1]\n",
    "    fn = binary_confusion_matrix[1][0]\n",
    "    fp = binary_confusion_matrix[0][1]\n",
    "    tn = binary_confusion_matrix[0][0]\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specifity = tn / (tn + fp)\n",
    "    ppv = tp / (tp + fp)\n",
    "    npv = tn / (tn + fn)\n",
    "    metrics = [binary_accracy, sensitivity, specifity, ppv, npv, binary_confusion_matrix]\n",
    "    return metrics\n",
    "\n",
    "# 加载模型并在测试集上进行预测\n",
    "results = {}\n",
    "metrics_names = ['Accuracy', 'Sensitivity', 'Specificity', 'PPV', 'NPV']\n",
    "\n",
    "for model_name in models.keys():\n",
    "    print(f\"\\n评估 {model_name} 模型...\")\n",
    "    \n",
    "    # 加载模型\n",
    "    model_path = f'weight/{model_name.lower().replace(\" \", \"_\")}.pkl'\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    \n",
    "    # 进行预测\n",
    "    predictions = model.predict_proba(data_test_final)\n",
    "    # 保存预测的结果\n",
    "    np.save(f'prediction/{model_name.lower().replace(\" \", \"_\")}_prediction.npy', predictions)\n",
    "    \n",
    "    # 计算 AUC\n",
    "    auc = roc_auc_score(y_true=data_test_y, y_score=predictions[:, 1])\n",
    "    \n",
    "    # 计算其他指标\n",
    "    metrics = cal_bin_metrics(y_true=data_test_y, y_pred=predictions)\n",
    "    \n",
    "    # 保存结果\n",
    "    results[model_name] = {\n",
    "        'AUC': auc,\n",
    "        'Metrics': dict(zip(metrics_names, metrics[:-1])),  # 不包含混淆矩阵\n",
    "        'Confusion Matrix': metrics[-1]\n",
    "    }\n",
    "    \n",
    "    # 打印结果\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    for metric_name, value in results[model_name]['Metrics'].items():\n",
    "        print(f\"{metric_name}: {value:.4f}\")\n",
    "    print(\"\\n混淆矩阵:\")\n",
    "    print(results[model_name]['Confusion Matrix'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_bin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
