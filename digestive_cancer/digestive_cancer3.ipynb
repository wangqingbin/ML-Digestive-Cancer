{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入所需要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sympy import im\n",
    "import xgboost\n",
    "import lightgbm\n",
    "import catboost\n",
    "import optuna\n",
    "import gc\n",
    "import warnings\n",
    "import logging\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
    "from optuna.samplers import TPESampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable     | Definition       | Key                                            |\n",
    "|--------------|------------------|------------------------------------------------|\n",
    "| index        | 病人编号         |                                                |\n",
    "| Source       | 病人来源         | 0：国外数据集 1：国内数据集                    |\n",
    "| Sex          | 性别             | 0：男 1：女                                    |\n",
    "| Age          | 年龄             |                                                |\n",
    "| BMI          | 身高体重比       |                                                |\n",
    "| Diagnostic   | 癌症类型         |                                                |\n",
    "| Stage        | 癌症分期         |                                                |\n",
    "| NLR          | 中性/淋巴        |                                                |\n",
    "| HGB          | 血红蛋白         |                                                |\n",
    "| Surgury      | 之前是否进行手术 | 0：未手术 1：已手术                            |\n",
    "| Chemo        | 是否同时进行化疗 | 0：否；1：是                                   |\n",
    "| Radiotherapy | 是否同时进行化疗 | 0：否；1：是                                   |\n",
    "| Drug         | 免疫药物         | 0：PD1/PDL1orCTLA4；1：Combo                   |\n",
    "| MSI          | 微卫星不稳定性   | 0：MSS； 1：MSI-H                              |\n",
    "| GeneMutation | 基因突变         | 0.0：hert2阴性；1.0：hert2阳性；2.0：K-RAS阳性 |\n",
    "| CPS          | 联合阳性评分     |                                                |\n",
    "| Ki67         | 细胞增殖标志物   |                                                |\n",
    "| Response     | 免疫应答         | 0：无应答；1：有应答                           |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"digestive_cancer.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标明哪些列是数值型，哪些是类别型\n",
    "category_columns = ['Sex', 'Diagnostic', 'Stage', 'Surgury', 'Chemo', 'Radiotherapy', 'Drug', 'MSI', 'GeneMutation']\n",
    "numeric_columns = ['Age', 'BMI', 'NLR', 'HGB', 'CPS', 'ki67']\n",
    "hospital_source = ['Source']\n",
    "target = ['Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算类别权重\n",
    "y = data['Response']\n",
    "scale_pos_weight = np.sum(y == 0) / np.sum(y == 1)  # 负类样本数 / 正类样本数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 划分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由于目前的数据集是将国内数据集和国外数据集合并到一起的，但两种数据集存在明显的差异，因此在划分训练集和测试集时，需要将两种数据集分开单独划分\n",
    "data_in = data[data['Source'] == 1]\n",
    "data_out = data[data['Source'] == 0]\n",
    "# 由于在划分训练集和测试集时，需要保证训练集和测试集的类别分布是相同的，除此之外，还要保证每个类别中癌症类别的分布也是相同的，因此需要组建Diagnostic和Response的联合变量\n",
    "data_in_stratify = data_in['Diagnostic'].astype(str) + '_' + data_in['Response'].astype(str)\n",
    "data_out_stratify = data_out['Diagnostic'].astype(str) + '_' + data_out['Response'].astype(str)\n",
    "# 区分数据的特征和目标\n",
    "data_in_X = data_in.drop(columns=['Response', 'Source'])\n",
    "data_in_y = data_in['Response']\n",
    "data_out_X = data_out.drop(columns=['Response', 'Source'])\n",
    "data_out_y = data_out['Response']\n",
    "# 划分训练集和测试集\n",
    "data_in_train_X, data_in_test_X, data_in_train_y, data_in_test_y = train_test_split(data_in_X, data_in_y, test_size=0.2, random_state=42, stratify=data_in_stratify)\n",
    "data_out_train_X, data_out_test_X, data_out_train_y, data_out_test_y = train_test_split(data_out_X, data_out_y, test_size=0.2, random_state=42, stratify=data_out_stratify)\n",
    "# 将两家医院的数据进行合并\n",
    "data_train_X = pd.concat([data_in_train_X, data_out_train_X], ignore_index=True)\n",
    "data_train_y = pd.concat([data_in_train_y, data_out_train_y], ignore_index=True)\n",
    "data_test_X = pd.concat([data_in_test_X, data_out_test_X], ignore_index=True)\n",
    "data_test_y = pd.concat([data_in_test_y, data_out_test_y], ignore_index=True)\n",
    "data_train_X.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将训练数据集和测试数据集的类别特征进行编码，无序的采用OneHotEncoder，有序的采用OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "# 定义有序和无序类别特征\n",
    "ordinal_features = ['Stage']  # 有序特征\n",
    "nominal_features = [col for col in category_columns if col not in ordinal_features]  # 无序特征\n",
    "\n",
    "# 创建编码器\n",
    "onehot_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "# 对训练集进行编码\n",
    "# 1. OneHot编码\n",
    "onehot_encoded = onehot_encoder.fit_transform(data_train_X[nominal_features])\n",
    "onehot_feature_names = onehot_encoder.get_feature_names_out(nominal_features)\n",
    "onehot_encoded_df = pd.DataFrame(onehot_encoded, columns=onehot_feature_names)\n",
    "\n",
    "# 2. Ordinal编码\n",
    "ordinal_encoded = ordinal_encoder.fit_transform(data_train_X[ordinal_features])\n",
    "ordinal_encoded_df = pd.DataFrame(ordinal_encoded, columns=ordinal_features)\n",
    "\n",
    "# 3. 合并数值特征和编码后的特征\n",
    "data_train_final = pd.concat([\n",
    "    data_train_X[numeric_columns].reset_index(drop=True),\n",
    "    onehot_encoded_df.reset_index(drop=True),\n",
    "    ordinal_encoded_df.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "# 对测试集进行编码(使用训练集的编码器)\n",
    "# 1. OneHot编码\n",
    "test_onehot_encoded = onehot_encoder.transform(data_test_X[nominal_features])\n",
    "test_onehot_encoded_df = pd.DataFrame(test_onehot_encoded, columns=onehot_feature_names)\n",
    "\n",
    "# 2. Ordinal编码\n",
    "test_ordinal_encoded = ordinal_encoder.transform(data_test_X[ordinal_features])\n",
    "test_ordinal_encoded_df = pd.DataFrame(test_ordinal_encoded, columns=ordinal_features)\n",
    "\n",
    "# 3. 合并数值特征和编码后的特征\n",
    "data_test_final = pd.concat([\n",
    "    data_test_X[numeric_columns].reset_index(drop=True),\n",
    "    test_onehot_encoded_df.reset_index(drop=True),\n",
    "    test_ordinal_encoded_df.reset_index(drop=True)\n",
    "], axis=1)\n",
    "data_train_X = data_train_final\n",
    "data_test_X = data_test_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义目标优化函数，以便使用optuna进行参数选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost模型的目标函数\n",
    "def train_model_category(trial, data_x, data_y):\n",
    "    '''\n",
    "    trial: optuna自带的默认参数, 用于提供各个参数调整范围\n",
    "    data_x: 训练数据的输入特征\n",
    "    data_y: 训练数据的标签\n",
    "    '''\n",
    "    # 定义交叉验证策略\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    # 定义模型需要调整的参数范围\n",
    "    # xgboost的参数网络\n",
    "    param_grid = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'booster': 'gbtree',\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 20, 200, step=5),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, step=0.05),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 7, step=1),\n",
    "        'random_state': 42,\n",
    "        'subsample': trial.suggest_float('subsample', 0.2, 1, step=0.05),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.2, 1, step=0.05),\n",
    "        'scale_pos_weight': scale_pos_weight,\n",
    "        'n_jobs': 20\n",
    "    }\n",
    "\n",
    "    total_preds = np.zeros(data_x.shape[0])\n",
    "    # 对5折数据进行for循环\n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(kfold.split(data_x, data_y)):\n",
    "        train_x, train_y = data_x.iloc[train_idx], data_y.iloc[train_idx]\n",
    "        valid_x, valid_y = data_x.iloc[valid_idx], data_y.iloc[valid_idx]\n",
    "        clf = xgboost.XGBClassifier(**param_grid)\n",
    "        clf.fit(train_x, train_y,\n",
    "                eval_set=[(train_x, train_y), (valid_x, valid_y)],\n",
    "                verbose=False, \n",
    "        )\n",
    "        \n",
    "        total_preds[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n",
    "        \n",
    "        del clf, train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "    \n",
    "    auc = roc_auc_score(data_y, total_preds)\n",
    "    print('Full AUC score %.6f' % auc) \n",
    "    return auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # lightgbm模型的目标函数\n",
    "# def train_model_category(trial, data_x, data_y):\n",
    "#     \"\"\"\n",
    "#     trial: optuna自带的默认参数, 用于提供各个参数调整范围\n",
    "#     data_x: 训练数据的输入特征\n",
    "#     data_y: 训练数据的标签\n",
    "#     \"\"\"\n",
    "#     # 定义交叉验证策略\n",
    "#     kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#     # 定义模型需要调整的参数范围\n",
    "#     # lightgbm的参数网络\n",
    "#     param_grid = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 20, 200,step=5),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3,step=0.05),\n",
    "#         'num_leaves': trial.suggest_int('num_leaves', 2**2, 2**5, step=4),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 3, 12, step=2),\n",
    "#         'colsample_bytree': trial.suggest_float('colsample_bytree', 0.2, 1, step=0.05),\n",
    "#         'subsample': trial.suggest_float('subsample', 0.2, 1, step=0.05),\n",
    "#         'reg_alpha': trial.suggest_float('reg_alpha', 0.2, 1, step=0.1),\n",
    "#         'random_state': 42,\n",
    "#     }\n",
    "\n",
    "#     total_preds = np.zeros(data_x.shape[0])\n",
    "#     # 对5折数据进行for循环\n",
    "#     for n_fold, (train_idx, valid_idx) in enumerate(kfold.split(data_x, data_y)):\n",
    "#         train_x, train_y = data_x.iloc[train_idx], data_y.iloc[train_idx]\n",
    "#         valid_x, valid_y = data_x.iloc[valid_idx], data_y.iloc[valid_idx]\n",
    "#         clf = lightgbm.LGBMClassifier(**param_grid)\n",
    "#         clf.fit(train_x, train_y,\n",
    "#                 eval_set=[(train_x, train_y), (valid_x, valid_y)]\n",
    "#         )\n",
    "        \n",
    "#         total_preds[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n",
    "        \n",
    "#         del clf, train_x, train_y, valid_x, valid_y\n",
    "#         gc.collect()\n",
    "    \n",
    "#     auc = roc_auc_score(data_y, total_preds)\n",
    "#     print('Full AUC score %.6f' % auc) \n",
    "#     return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # randomforest模型的目标函数\n",
    "# def train_model_category(trial, data_x, data_y):\n",
    "#     '''\n",
    "#     trial: optuna自带的默认参数, 用于提供各个参数调整范围\n",
    "#     data_x: 训练数据的输入特征\n",
    "#     data_y: 训练数据的标签\n",
    "#     '''\n",
    "#     # 定义交叉验证策略\n",
    "#     kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#     # 定义模型需要调整的参数范围\n",
    "#     # xgboost的参数网络\n",
    "#     param_grid = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 20, 200, step=5),\n",
    "#         'class_weight': 'balanced',\n",
    "#         'random_state': 42,\n",
    "#         'n_jobs': -1\n",
    "#     }\n",
    "\n",
    "#     total_preds = np.zeros(data_x.shape[0])\n",
    "#     # 对5折数据进行for循环\n",
    "#     for n_fold, (train_idx, valid_idx) in enumerate(kfold.split(data_x, data_y)):\n",
    "#         train_x, train_y = data_x.iloc[train_idx], data_y.iloc[train_idx]\n",
    "#         valid_x, valid_y = data_x.iloc[valid_idx], data_y.iloc[valid_idx]\n",
    "#         clf = RandomForestClassifier(**param_grid)\n",
    "#         clf.fit(train_x, train_y)\n",
    "        \n",
    "#         total_preds[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n",
    "        \n",
    "#         del clf, train_x, train_y, valid_x, valid_y\n",
    "#         gc.collect()\n",
    "    \n",
    "#     auc = roc_auc_score(data_y, total_preds)\n",
    "#     print('Full AUC score %.6f' % auc) \n",
    "#     return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义optuna优化器\n",
    "study = optuna.create_study(direction='maximize', study_name='xgboost', sampler=TPESampler(seed=42))\n",
    "func = lambda trial: train_model_category(trial, data_train_X, data_train_y)\n",
    "study.optimize(func, n_trials=300)\n",
    "print('最佳参数: ', study.best_params)\n",
    "print('最佳trial: ', study.best_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用最优参数定义模型，并进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义xgboost模型\n",
    "clf = xgboost.XGBClassifier(random_state=42, scale_pos_weight=scale_pos_weight, n_jobs=-1, **study.best_params)\n",
    "clf.fit(data_train_X, data_train_y, \n",
    "        verbose=False\n",
    ")\n",
    "import pickle\n",
    "# 保存训练好的模型\n",
    "model_name = 'xgboost'\n",
    "save_path = f'weight/{model_name.lower().replace(\" \", \"_\")}.pkl'\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(clf, f)\n",
    "print(f\"Model saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义lightgbm模型\n",
    "# clf = lightgbm.LGBMClassifier(random_state=42, scale_pos_weight=scale_pos_weight, n_jobs=-1, **study.best_params)\n",
    "# clf.fit(data_train_X, data_train_y\n",
    "# )\n",
    "# # 保存训练好的模型\n",
    "# clf.booster_.save_model('weight/lightgbm_model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义random forest模型\n",
    "# clf = RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1, **study.best_params)\n",
    "# clf.fit(data_train_X, data_train_y)\n",
    "# # 保存训练好的模型\n",
    "# # # 保存训练好的模型\n",
    "# clf.save_model('weight/randomforest_model.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测测试集，并计算相应指标，绘图等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_bin_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    the function is used to calculate the corresponding metrics for binary classification,\n",
    "    including 二分类准确率, 灵敏度, 特异性, PPV, NPV, AUC\n",
    "    :param y_true: 一维数组标签, [1, 0, 1, ...]\n",
    "    :param y_pred: 二维预测数组, [num_sample, 2]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    binary_accracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    # 利用sklearn的接口计算得到混淆矩阵\n",
    "    binary_confusion_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
    "    # 接下来利用二分类的混淆矩阵计算各种指标，包括灵敏度，特异性，PPV, NPV\n",
    "    tp = binary_confusion_matrix[1][1]\n",
    "    fn = binary_confusion_matrix[1][0]\n",
    "    fp = binary_confusion_matrix[0][1]\n",
    "    tn = binary_confusion_matrix[0][0]\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specifity = tn / (tn + fp)\n",
    "    ppv = tp / (tp + fp)\n",
    "    npv = tn / (tn + fn)\n",
    "    metrics = [binary_accracy, sensitivity, specifity, ppv, npv, binary_confusion_matrix]\n",
    "    return metrics\n",
    "\n",
    "predictions = clf.predict_proba(data_test_X)\n",
    "# 保存预测的结果\n",
    "np.save('prediction/xgboost_prediction.npy', predictions)\n",
    "auc = roc_auc_score(y_true=data_test_y, y_score=predictions[:, 1])\n",
    "print(auc)\n",
    "metrics = cal_bin_metrics(y_true=data_test_y, y_pred=predictions)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_bin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
